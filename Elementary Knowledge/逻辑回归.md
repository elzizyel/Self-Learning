<center><font size = 10>Logistics Regression</font></center>

# 1. 基础介绍

sigmoid函数:
$$
g(z) = \frac{1}{1 + e^{-z}}
$$


其中z为:
$$
z = W^TX
$$

推导:
$$
p = \frac{1}{1 + e^{-W^TX}} \ \ \rightarrow \ \ \ln(\frac{p}{1-p}) = W^TX
$$


结论:

​	所以假设我们已经训练好了LR模型，已经知道W的值了，将其带入$g(z)$， 我们求出来的是一个概率。即这个$X$它的y=1的概率。

​	其实就相当于将线性回归的结果扔到sigmoid函数里面去，变成了预测该样本被分为1的概率。

 

最大似然估计:

1. 即利用已知的样本，反推最大概率导致这样结果的参数值。

2. 因为样本独立同分布，所以其似然函数为:$ L(\theta) = p(X | \theta) = \prod_{i=1}^{N}p(x_i | \theta)$

3. 概率密度函数: PDF； 其下面积为1，$P(x < a) = \int_{-\inf}^{a} f(x) \mathrm{d}x$，其中$f(x)$即为概率密度函数
4. 求解似然函数，找出使得$L$最大的情况下,$\theta$的值
5. $\hat{\theta} = \mathop{\arg\max}_{\theta}\ln (L(\theta)) = \mathop{\arg\max}_{\theta} \sum_{i=1}^{N} \ln p(x_i | \theta)$
6. 即对$\theta$求偏导，找出偏导公式=0时，$\theta$的值



逻辑回归求解

1. 假设有N个二分类样本$Y_1, ..., Y_n$, 其对应的x值的向量为$X_1, ..., X_n$。
2. 设第i个样本$p_i = P(y_i = 1 | X_i)$为给定$X_i$条件下得到的结果$y_i = 1$的条件概率；相同的可以得到$1 - p_i = P(y_i = 0 | X_i)$为给定$X_i$条件下得到的结果$y_i = 0$的条件概率。
3. 总结上式，可以得出$P(y_i) = p_i^{y_i}(1 - p_i)^{1 - y_i}$
4. 因为N个样本独立同分布，所以他们的似然函数为$L = \prod_{i=1}^{N} p_i^{y_i}(1 - p_i)^{1 - y_i}$
5. 所以目标确定为求使得$L$最大的$W$
6. 对$\beta_j$求偏导，求解公式(直接列公式用极大似然求解或者梯度下降)
7. 总结: 对似然函数使用公式或者梯度下降的方式求解，得到权重，该权重使得似然函数的值最大。



1. $g(z) = \frac{1}{1 + e^{W^TX}}$
2. $P(True) = (g(w, x_i))^{y_i} * (1 - g(w, x_i))^{1 - y_i}$
3. 令，$h_{\theta}(x) = \frac{1}{1 + e^{-z}}$
4. 则，$h_{\theta}(x)$的似然函数为: $L(\theta) = \prod_{i=1}^N (h_{\theta}(x_i))^{y_i} * (1 - h_{\theta(x_i)})^{1 - y_i}$

5. 对$L(\theta)$取log时其从连乘形式变为连加形式: $l(\theta) = \log L(\theta) = \sum_{i=1}^{N}(y_i \log (h_{\theta}(x_i)) + (1 - y_i) \log(1 - h_{\theta}(x_i))$

6. 对上式加上负号，即得到了交叉熵损失函数。
7. 对损失函数求导，直接列公式或者梯度下降，求使得损失函数最小时的$W^T$

8. $\frac{\partial J(\theta)}{\partial \theta} = \frac{1}{n} \sum_{i=1}^{N} (h_{\theta}(x_i) - y_i) * x_i^{j}$





# 2. 代码

```python
import numpy as np
import pandas as pd
import random
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler

# Generate Data
x1 = []
x2 = []
y = []
for i in range(10000):
    x1.append(random.uniform(-1000, 1000))
    x2.append(random.uniform(0, 10000))
    y.append(random.choice([0,1]))
    
    
scaler = StandardScaler()
data = sclaer.fit_transform([x1, x2])
data = pd.DataFrame(data, columns=[x1, x2])
data['target'] = y

# Train Model
y = data['target']
X = data[[col for col in data.columns if col != 'target']]
model = LogisticRegression()
model.fit(X, y)
print(model.intercept_)
print(model.coef_)
```

p.s. 其中的model.coef_为z内的参数， 即需要$1 / （1 + e^{-coef*x}）$算出其概率值。

p.s. 但是使用model.predict(X_test)可以直接求出其类别(自动使用0.5作为threshold)

