{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "air_reserve = pd.read_csv('air_reserve.csv').rename(columns={'air_store_id':'store_id'})\n",
    "hpg_reserve = pd.read_csv('hpg_reserve.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "air_store = pd.read_csv('air_store_info.csv').rename(columns={'air_store_id':'store_id'})\n",
    "hpg_store = pd.read_csv('hpg_store_info.csv').rename(columns={'hpg_store_id':'store_id'})\n",
    "air_visit = pd.read_csv('air_visit_data.csv').rename(columns={'air_store_id':'store_id'})\n",
    "store_id_map = pd.read_csv('store_id_relation.csv').set_index('hpg_store_id',drop=False)\n",
    "date_info = pd.read_csv('date_info.csv').rename(columns={'calendar_date': 'visit_date'}).drop('day_of_week',axis=1)\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0\n",
       "1  air_00a91d42b08b08d9_2017-04-24         0\n",
       "2  air_00a91d42b08b08d9_2017-04-25         0\n",
       "3  air_00a91d42b08b08d9_2017-04-26         0\n",
       "4  air_00a91d42b08b08d9_2017-04-27         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['visit_date'] = submission['id'].str[-10:]\n",
    "submission['store_id'] = submission['id'].str[:-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors  visit_date              store_id\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0  2017-04-23  air_00a91d42b08b08d9\n",
       "1  air_00a91d42b08b08d9_2017-04-24         0  2017-04-24  air_00a91d42b08b08d9\n",
       "2  air_00a91d42b08b08d9_2017-04-25         0  2017-04-25  air_00a91d42b08b08d9\n",
       "3  air_00a91d42b08b08d9_2017-04-26         0  2017-04-26  air_00a91d42b08b08d9\n",
       "4  air_00a91d42b08b08d9_2017-04-27         0  2017-04-27  air_00a91d42b08b08d9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 6  \n",
       "3                 2  \n",
       "4                 5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_reserve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_reserve['visit_date'] = air_reserve['visit_datetime'].str[:10]\n",
    "air_reserve['reserve_date'] = air_reserve['reserve_datetime'].str[:10]\n",
    "air_reserve['dow'] = pd.to_datetime(air_reserve['visit_date']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors  visit_date reserve_date  dow  \n",
       "0                 1  2016-01-01   2016-01-01    4  \n",
       "1                 3  2016-01-01   2016-01-01    4  \n",
       "2                 6  2016-01-01   2016-01-01    4  \n",
       "3                 2  2016-01-01   2016-01-01    4  \n",
       "4                 5  2016-01-01   2016-01-01    4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_reserve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].str[:10]\n",
    "hpg_reserve['reserve_date'] = hpg_reserve['reserve_datetime'].str[:10]\n",
    "hpg_reserve['dow'] = pd.to_datetime(hpg_reserve['visit_date']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id       visit_datetime     reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f  2016-01-01 11:00:00  2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47  2016-01-01 13:00:00  2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5  2016-01-01 16:00:00  2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a  2016-01-01 17:00:00  2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2  2016-01-01 17:00:00  2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors  visit_date reserve_date  dow  \n",
       "0                 1  2016-01-01   2016-01-01    4  \n",
       "1                 3  2016-01-01   2016-01-01    4  \n",
       "2                 2  2016-01-01   2016-01-01    4  \n",
       "3                 5  2016-01-01   2016-01-01    4  \n",
       "4                13  2016-01-01   2016-01-01    4  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_reserve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_visit['id'] = air_visit['store_id'] + '_' + air_visit['visit_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id  visit_date  visitors                               id\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25  air_ba937bf13d40fb24_2016-01-13\n",
       "1  air_ba937bf13d40fb24  2016-01-14        32  air_ba937bf13d40fb24_2016-01-14\n",
       "2  air_ba937bf13d40fb24  2016-01-15        29  air_ba937bf13d40fb24_2016-01-15\n",
       "3  air_ba937bf13d40fb24  2016-01-16        22  air_ba937bf13d40fb24_2016-01-16\n",
       "4  air_ba937bf13d40fb24  2016-01-18         6  air_ba937bf13d40fb24_2016-01-18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_visit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg_reserve['store_id'] = hpg_reserve['store_id'].map(store_id_map['air_store_id']).fillna(hpg_reserve['store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>dow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id       visit_datetime     reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f  2016-01-01 11:00:00  2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47  2016-01-01 13:00:00  2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5  2016-01-01 16:00:00  2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a  2016-01-01 17:00:00  2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2  2016-01-01 17:00:00  2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors  visit_date reserve_date  dow  \n",
       "0                 1  2016-01-01   2016-01-01    4  \n",
       "1                 3  2016-01-01   2016-01-01    4  \n",
       "2                 2  2016-01-01   2016-01-01    4  \n",
       "3                 5  2016-01-01   2016-01-01    4  \n",
       "4                13  2016-01-01   2016-01-01    4  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_reserve.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg_store['store_id'] = hpg_store['store_id'].map(store_id_map['air_store_id']).fillna(hpg_store['store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg_store.rename(columns={'hpg_genre_name':'air_genre_name', 'hpg_area_name':'air_area_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_6622b62385aec8bf</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_e9e068dd49c5fa00</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_2976f7acb4b3a3bc</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_e51a522e098f024c</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_e3d0e1519894f275</td>\n",
       "      <td>Japanese style</td>\n",
       "      <td>Tōkyō-to Setagaya-ku Taishidō</td>\n",
       "      <td>35.643675</td>\n",
       "      <td>139.668221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id  air_genre_name                  air_area_name  \\\n",
       "0  hpg_6622b62385aec8bf  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "1  hpg_e9e068dd49c5fa00  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "2  hpg_2976f7acb4b3a3bc  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "3  hpg_e51a522e098f024c  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "4  hpg_e3d0e1519894f275  Japanese style  Tōkyō-to Setagaya-ku Taishidō   \n",
       "\n",
       "    latitude   longitude  \n",
       "0  35.643675  139.668221  \n",
       "1  35.643675  139.668221  \n",
       "2  35.643675  139.668221  \n",
       "3  35.643675  139.668221  \n",
       "4  35.643675  139.668221  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([air_visit, submission]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dow'] = pd.to_datetime(data['visit_date']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_info['holiday_flg2'] = pd.to_datetime(date_info['visit_date']).dt.dayofweek\n",
    "date_info['holiday_flg2'] = ((date_info['holiday_flg2'] > 4) | (date_info['holiday_flg'] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>holiday_flg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date  holiday_flg  holiday_flg2\n",
       "0  2016-01-01            1             1\n",
       "1  2016-01-02            1             1\n",
       "2  2016-01-03            1             1\n",
       "3  2016-01-04            0             0\n",
       "4  2016-01-05            0             0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_store['air_area_name0'] = air_store['air_area_name'].apply(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_store['air_genre_name'] = lbl.fit_transform(air_store['air_genre_name'])\n",
    "air_store['air_area_name0'] = lbl.fit_transform(air_store['air_area_name0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>air_area_name0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>6</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>6</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>6</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>6</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>6</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7               6  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc               6  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e               6  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2               6  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e               6  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "    latitude   longitude  air_area_name0  \n",
       "0  34.695124  135.197852               3  \n",
       "1  34.695124  135.197852               3  \n",
       "2  34.695124  135.197852               3  \n",
       "3  34.695124  135.197852               3  \n",
       "4  35.658068  139.751599               7  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_store.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['visitors'] = np.log1p(data['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(air_store, on='store_id', how='left')\n",
    "data = data.merge(date_info[['visit_date', 'holiday_flg', 'holiday_flg2']], on=['visit_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>air_area_name0</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>holiday_flg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-13</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>3.258097</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-14</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-15</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-16</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24_2016-01-18</td>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id              store_id  visit_date  \\\n",
       "0  air_ba937bf13d40fb24_2016-01-13  air_ba937bf13d40fb24  2016-01-13   \n",
       "1  air_ba937bf13d40fb24_2016-01-14  air_ba937bf13d40fb24  2016-01-14   \n",
       "2  air_ba937bf13d40fb24_2016-01-15  air_ba937bf13d40fb24  2016-01-15   \n",
       "3  air_ba937bf13d40fb24_2016-01-16  air_ba937bf13d40fb24  2016-01-16   \n",
       "4  air_ba937bf13d40fb24_2016-01-18  air_ba937bf13d40fb24  2016-01-18   \n",
       "\n",
       "   visitors  dow  air_genre_name                 air_area_name   latitude  \\\n",
       "0  3.258097    2               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "1  3.496508    3               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2  3.401197    4               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "3  3.135494    5               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "4  1.945910    0               4  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "\n",
       "    longitude  air_area_name0  holiday_flg  holiday_flg2  \n",
       "0  139.751599               7            0             0  \n",
       "1  139.751599               7            0             0  \n",
       "2  139.751599               7            0             0  \n",
       "3  139.751599               7            0             1  \n",
       "4  139.751599               7            0             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(L):\n",
    "    result = None\n",
    "    for l in L:\n",
    "        if result is None:\n",
    "            result = l\n",
    "        else:\n",
    "            try:\n",
    "                result[l.columns.tolist()] = l\n",
    "            except:\n",
    "                print(l.head())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_merge(data1, data2, on):\n",
    "    if not isinstance(on, list):\n",
    "        on = [on]\n",
    "    if (set(on) & set(data2.columns)) != set(on):\n",
    "        data2_temp = data2.reset_index()\n",
    "    else:\n",
    "        data2_temp = data2.copy()\n",
    "    columns = [f for f in data2.columns if f not in on]\n",
    "    result = data1.merge(data2_temp, on=on, how='left')\n",
    "    result = result[columns]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_of_days(day1, day2):\n",
    "    days = (parse(day1[:10]) - parse(day2[:10])).days\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_add_days(start_date, days):\n",
    "    end_date = parse(start_date[:10]) + timedelta(days=days)\n",
    "    end_date = end_date.strftime('%Y-%m-%d')\n",
    "    return end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(end_date, n_day):\n",
    "    label_end_date = date_add_days(end_date, n_day)\n",
    "    label = data[(data['visit_date'] < label_end_date) & (data['visit_date'] >= end_date)].copy()\n",
    "    label['end_date'] = end_date\n",
    "    label['diff_day'] = label['visit_date'].apply(lambda x: diff_of_days(x, end_date))\n",
    "    label['month'] = label['visit_date'].str[5:7].astype(int)\n",
    "    label['year'] = label['visit_date'].str[:4].astype(int)\n",
    "    for i in [3, 2, 1, -1]:\n",
    "        date_info_temp = date_info.copy()\n",
    "        date_info_temp['visit_date'] = date_info_temp['visit_date'].apply(lambda x: date_add_days(x,i))\n",
    "        date_info_temp.rename(columns={'holiday_flg':'ahead_holiday_{}'.format(i),\n",
    "                                       'holiday_flg2':'ahead_holiday2_{}'.format(i)},\n",
    "                             inplace=True)\n",
    "        label = label.merge(date_info_temp, on=['visit_date'], how='left')\n",
    "    label = label.reset_index(drop=True)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_tmp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_tmp.groupby(['store_id'], as_index=False)['visitors'].agg({'store_min{}'.format(n_day): 'min',\n",
    "                                                                            'store_mean{}'.format(n_day): 'mean',\n",
    "                                                                            'store_median{}'.format(n_day): 'median',\n",
    "                                                                            'store_max{}'.format(n_day): 'max',\n",
    "                                                                            'store_count{}'.format(n_day): 'count',\n",
    "                                                                             'store_std{}'.format(n_day): 'std',\n",
    "                                                                             'store_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_exp_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_tmp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_tmp['visit_date'] = data_tmp['visit_date'].apply(lambda x: diff_of_days(key[0], x))\n",
    "    data_tmp['weight'] = data_tmp['visit_date'].apply(lambda x: .985**x)\n",
    "    data_tmp['visitors'] = data_tmp['visitors'] * data_tmp['weight']\n",
    "    result1 = data_tmp.groupby(['store_id'], as_index=False)['visitors'].agg({'store_exp_mean{}'.format(n_day): 'sum'})\n",
    "    result2 = data_tmp.groupby(['store_id'], as_index=False)['weight'].agg({'store_exp_weight_sum{}'.format(n_day): 'sum'})\n",
    "    result = result1.merge(result2, on=['store_id'], how='left')\n",
    "    result['store_exp_mean{}'.format(n_day)] = result['store_exp_mean{}'.format(n_day)] / result['store_exp_weight_sum{}'.format(n_day)]\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_week_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_tmp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_tmp.groupby(['store_id', 'dow'], as_index=False)['visitors'].agg({'store_dow_min'.format(n_day): 'min',\n",
    "                                                                                   'store_dow_mean{}'.format(n_day): 'mean',\n",
    "                                                                                     'store_dow_median{}'.format(n_day): 'median',\n",
    "                                                                                     'store_dow_max{}'.format(n_day): 'max',\n",
    "                                                                                     'store_dow_count{}'.format(n_day): 'count',\n",
    "                                                                                     'store_dow_std{}'.format(n_day): 'std',\n",
    "                                                                                     'store_dow_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['store_id', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_week_diff_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_tmp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_tmp.set_index(['store_id', 'visit_date'])['visitors'].unstack()\n",
    "    result = result.diff(axis=1).iloc[:,1:]\n",
    "    c = result.columns\n",
    "    result['store_diff_mean'] = np.abs(result[c]).mean(axis=1)\n",
    "    result['store_diff_std'] = result[c].std(axis=1)\n",
    "    result['store_diff_max'] = result[c].max(axis=1)\n",
    "    result['store_diff_min'] = result[c].min(axis=1)\n",
    "    result = left_merge(label, result[['store_diff_mean', 'store_diff_std', 'store_diff_max', 'store_diff_min']],\n",
    "                        on=['store_id']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_all_week_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_tmp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result_tmp = data_tmp.groupby(['store_id', 'dow'], as_index=False)['visitors'].agg({'store_dow_mean{}'.format(n_day): 'mean',\n",
    "                                                                                        'store_dow_median{}'.format(n_day): 'median',\n",
    "                                                                                        'store_dow_sum{}'.format(n_day): 'max',\n",
    "                                                                                        'store_dow_count{}'.format(n_day): 'count'})\n",
    "    result = pd.DataFrame()\n",
    "    for i in range(7):\n",
    "        result_sub = result_tmp[result_tmp['dow'] == i].copy()\n",
    "        result_sub = result_sub.set_index('store_id')\n",
    "        result_sub = result_sub.add_prefix(str(i))\n",
    "        result_sub = left_merge(label, result_sub, on=['store_id']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_week_exp_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['visitors2'] = data_temp['visitors']\n",
    "    result = None\n",
    "    for i in [0.9,0.95,0.97,0.98,0.985,0.99,0.999,0.9999]:\n",
    "        data_temp['weight'] = data_temp['visit_date'].apply(lambda x: i**x)\n",
    "        data_temp['visitors1'] = data_temp['visitors'] * data_temp['weight']\n",
    "        data_temp['visitors2'] = data_temp['visitors2'] * data_temp['weight']\n",
    "        result1 = data_temp.groupby(['store_id', 'dow'], as_index=False)['visitors1'].agg({'store_dow_exp_mean{}_{}'.format(n_day,i): 'sum'})\n",
    "        result3 = data_temp.groupby(['store_id', 'dow'], as_index=False)['visitors2'].agg({'store_dow_exp_mean2{}_{}'.format(n_day, i): 'sum'})\n",
    "        result2 = data_temp.groupby(['store_id', 'dow'], as_index=False)['weight'].agg({'store_dow_exp_weight_sum{}_{}'.format(n_day,i): 'sum'})\n",
    "        result_temp = result1.merge(result2, on=['store_id', 'dow'], how='left')\n",
    "        result_temp = result_temp.merge(result3, on=['store_id', 'dow'], how='left')\n",
    "        result_temp['store_dow_exp_mean{}_{}'.format(n_day,i)] = result_temp['store_dow_exp_mean{}_{}'.format(n_day,i)]/result_temp['store_dow_exp_weight_sum{}_{}'.format(n_day,i)]\n",
    "        result_temp['store_dow_exp_mean2{}_{}'.format(n_day, i)] = result_temp[ 'store_dow_exp_mean2{}_{}'.format(n_day, i)]/result_temp['store_dow_exp_weight_sum{}_{}'.format(n_day, i)]\n",
    "        if result is None:\n",
    "            result = result_temp\n",
    "        else:\n",
    "            result = result.merge(result_temp, on=['store_id','dow'], how='left')\n",
    "    result = left_merge(label, result, on=['store_id', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_holiday_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result1 = data_temp.groupby(['store_id', 'holiday_flg'], as_index=False)['visitors'].agg({'store_holiday_min{}'.format(n_day): 'min',\n",
    "                                                                                              'store_holiday_mean{}'.format(n_day): 'mean',\n",
    "                                                                                              'store_holiday_median{}'.format(n_day): 'median',\n",
    "                                                                                              'store_holiday_max{}'.format(n_day): 'max',\n",
    "                                                                                              'store_holiday_count{}'.format(n_day): 'count',\n",
    "                                                                                              'store_holiday_std{}'.format(n_day): 'std',\n",
    "                                                                                              'store_holiday_skew{}'.format(n_day): 'skew'})\n",
    "    result1 = left_merge(label, result1, on=['store_id', 'holiday_flg']).fillna(0)\n",
    "    result2 = data_temp.groupby(['store_id', 'holiday_flg2'], as_index=False)['visitors'].agg({'store_holiday2_min{}'.format(n_day): 'min',\n",
    "                                                                                               'store_holiday2_mean{}'.format(n_day): 'mean',\n",
    "                                                                                               'store_holiday2_median{}'.format(n_day): 'median',\n",
    "                                                                                               'store_holiday2_max{}'.format(n_day): 'max',\n",
    "                                                                                               'store_holiday2_count{}'.format(n_day): 'count',\n",
    "                                                                                               'store_holiday2_std{}'.format(n_day): 'std',\n",
    "                                                                                               'store_holiday2_skew{}'.format(n_day): 'skew'})\n",
    "    result2 = left_merge(label, result2, on=['store_id', 'holiday_flg2']).fillna(0)\n",
    "    result = pd.concat([result1, result2], axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0],-n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['air_genre_name'], as_index=False)['visitors'].agg({'genre_min{}'.format(n_day): 'min',\n",
    "                                                                                    'genre_mean{}'.format(n_day): 'mean',\n",
    "                                                                                    'genre_median{}'.format(n_day): 'median',\n",
    "                                                                                    'genre_max{}'.format(n_day): 'max',\n",
    "                                                                                    'genre_count{}'.format(n_day): 'count',\n",
    "                                                                                    'genre_std{}'.format(n_day): 'std',\n",
    "                                                                                    'genre_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['air_genre_name']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_exp_visitor_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['weight'] = data_temp['visit_date'].apply(lambda x: 0.985**x)\n",
    "    data_temp['visitors'] = data_temp['visitors'] * data_temp['weight']\n",
    "    result1 = data_temp.groupby(['air_genre_name'], as_index=False)['visitors'].agg({'genre_exp_mean{}'.format(n_day): 'sum'})\n",
    "    result2 = data_temp.groupby(['air_genre_name'], as_index=False)['weight'].agg({'genre_exp_weight_sum{}'.format(n_day): 'sum'})\n",
    "    result = result1.merge(result2, on=['air_genre_name'], how='left')\n",
    "    result['genre_exp_mean{}'.format(n_day)] = result['genre_exp_mean{}'.format(n_day)]/result['genre_exp_weight_sum{}'.format(n_day)]\n",
    "    result = left_merge(label, result, on=['air_genre_name']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_week_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    result = data_temp.groupby(['air_genre_name', 'dow'], as_index=False)['visitors'].agg({'genre_dow_min{}'.format(n_day): 'min',\n",
    "                                                                                           'genre_dow_mean{}'.format(n_day): 'mean',\n",
    "                                                                                           'genre_dow_median{}'.format(n_day): 'median',\n",
    "                                                                                           'genre_dow_max{}'.format(n_day): 'max',\n",
    "                                                                                           'genre_dow_count{}'.format(n_day): 'count',\n",
    "                                                                                           'genre_dow_std{}'.format(n_day): 'std',\n",
    "                                                                                           'genre_dow_skew{}'.format(n_day): 'skew'})\n",
    "    result = left_merge(label, result, on=['air_genre_name', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genre_week_exp_feat(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_temp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_temp['visit_date'] = data_temp['visit_date'].apply(lambda x: diff_of_days(key[0],x))\n",
    "    data_temp['weight'] = data_temp['visit_date'].apply(lambda x: 0.985**x)\n",
    "    data_temp['visitors'] = data_temp['visitors'] * data_temp['weight']\n",
    "    result1 = data_temp.groupby(['air_genre_name', 'dow'], as_index=False)['visitors'].agg({'genre_dow_exp_mean{}'.format(n_day): 'sum'})\n",
    "    result2 = data_temp.groupby(['air_genre_name', 'dow'], as_index=False)['weight'].agg({'genre_dow_exp_weight_sum{}'.format(n_day): 'sum'})\n",
    "    result = result1.merge(result2, on=['air_genre_name', 'dow'], how='left')\n",
    "    result['genre_dow_exp_mean{}'.format(n_day)] = result['genre_dow_exp_mean{}'.format(n_day)]/result['genre_dow_exp_weight_sum{}'.format(n_day)]\n",
    "    result = left_merge(label, result, on=['air_genre_name', 'dow']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_last_time(label, key, n_day):\n",
    "    start_date = date_add_days(key[0], -n_day)\n",
    "    data_tmp = data[(data.visit_date < key[0]) & (data.visit_date > start_date)].copy()\n",
    "    data_tmp = data_tmp.sort_values('visit_date')\n",
    "    result = data_tmp.groupby('store_id')['visit_date'].agg({'first_time': lambda x: diff_of_days(key[0], np.min(x)),\n",
    "                                                            'last_time': lambda x: diff_of_days(key[0], np.max(x)),})\n",
    "    result = left_merge(label, result, on=['store_id']).fillna(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# air_reserve\n",
    "def get_reserve_feat(label,key):\n",
    "    label_end_date = date_add_days(key[0], key[1])\n",
    "    air_reserve_temp = air_reserve[(air_reserve.visit_date >= key[0]) &             # key[0] 是'2017-04-23'\n",
    "                                   (air_reserve.visit_date < label_end_date) &      # label_end_date 是'2017-05-31'\n",
    "                                   (air_reserve.reserve_date < key[0])].copy()\n",
    "    air_reserve_temp = air_reserve_temp.merge(air_store,on='store_id',how='left')\n",
    "    air_reserve_temp['diff_time'] = (pd.to_datetime(air_reserve['visit_datetime'])-pd.to_datetime(air_reserve['reserve_datetime'])).dt.days\n",
    "    air_reserve_temp = air_reserve_temp.merge(air_store,on='store_id')\n",
    "    air_result = air_reserve_temp.groupby(['store_id', 'visit_date'])['reserve_visitors'].agg({'air_reserve_visitors': 'sum',\n",
    "                                                                                               'air_reserve_count': 'count'})\n",
    "    air_store_diff_time_mean = air_reserve_temp.groupby(['store_id', 'visit_date'])['diff_time'].agg({'air_store_diff_time_mean': 'mean'})\n",
    "    air_diff_time_mean = air_reserve_temp.groupby(['visit_date'])['diff_time'].agg({'air_diff_time_mean': 'mean'})\n",
    "    air_result = air_result.unstack().fillna(0).stack()\n",
    "    air_date_result = air_reserve_temp.groupby(['visit_date'])['reserve_visitors'].agg({'air_date_visitors': 'sum',\n",
    "                                                                                        'air_date_count': 'count'})\n",
    "    hpg_reserve_temp = hpg_reserve[(hpg_reserve.visit_date >= key[0]) & (hpg_reserve.visit_date < label_end_date) & (hpg_reserve.reserve_date < key[0])].copy()\n",
    "    hpg_reserve_temp['diff_time'] = (pd.to_datetime(hpg_reserve['visit_datetime']) - pd.to_datetime(hpg_reserve['reserve_datetime'])).dt.days\n",
    "    hpg_result = hpg_reserve_temp.groupby(['store_id', 'visit_date'])['reserve_visitors'].agg({'hpg_reserve_visitors': 'sum',\n",
    "                                                                                               'hpg_reserve_count': 'count'})\n",
    "    hpg_result = hpg_result.unstack().fillna(0).stack()\n",
    "    hpg_date_result = hpg_reserve_temp.groupby(['visit_date'])['reserve_visitors'].agg({'hpg_date_visitors': 'sum',\n",
    "                                                                                        'hpg_date_count': 'count'})\n",
    "    hpg_store_diff_time_mean = hpg_reserve_temp.groupby(['store_id', 'visit_date'])['diff_time'].agg({'hpg_store_diff_time_mean': 'mean'})\n",
    "    hpg_diff_time_mean = hpg_reserve_temp.groupby(['visit_date'])['diff_time'].agg({'hpg_diff_time_mean': 'mean'})\n",
    "    air_result = left_merge(label, air_result, on=['store_id','visit_date']).fillna(0)\n",
    "    air_store_diff_time_mean = left_merge(label, air_store_diff_time_mean, on=['store_id', 'visit_date']).fillna(0)\n",
    "    hpg_result = left_merge(label, hpg_result, on=['store_id', 'visit_date']).fillna(0)\n",
    "    hpg_store_diff_time_mean = left_merge(label, hpg_store_diff_time_mean, on=['store_id', 'visit_date']).fillna(0)\n",
    "    air_date_result = left_merge(label, air_date_result, on=['visit_date']).fillna(0)\n",
    "    air_diff_time_mean = left_merge(label, air_diff_time_mean, on=['visit_date']).fillna(0)\n",
    "    hpg_date_result = left_merge(label, hpg_date_result, on=['visit_date']).fillna(0)\n",
    "    hpg_diff_time_mean = left_merge(label, hpg_diff_time_mean, on=['visit_date']).fillna(0)\n",
    "    result = pd.concat([air_result,\n",
    "                        hpg_result,\n",
    "                        air_date_result,\n",
    "                        hpg_date_result,\n",
    "                        air_store_diff_time_mean,\n",
    "                        hpg_store_diff_time_mean,\n",
    "                        air_diff_time_mean,\n",
    "                        hpg_diff_time_mean],axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second feature\n",
    "def second_feat(result):\n",
    "    result['store_mean_14_28_rate'] = result['store_mean14']/(result['store_mean28']+0.01)\n",
    "    result['store_mean_28_56_rate'] = result['store_mean28'] / (result['store_mean56'] + 0.01)\n",
    "    result['store_mean_56_1000_rate'] = result['store_mean56'] / (result['store_mean1000'] + 0.01)\n",
    "    result['genre_mean_28_56_rate'] = result['genre_mean28'] / (result['genre_mean56'] + 0.01)\n",
    "    result['sgenre_mean_56_1000_rate'] = result['genre_mean56'] / (result['genre_mean1000'] + 0.01)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作训练集\n",
    "def make_feats(end_date,n_day):\n",
    "    t0 = time.time()\n",
    "    key = end_date,n_day\n",
    "    print('data key：{}'.format(key))\n",
    "    print('add label')\n",
    "    label = get_label(end_date,n_day)\n",
    "\n",
    "    print('make features...')\n",
    "    result = [label]\n",
    "    result.append(get_store_visitor_feat(label, key, 1000))        # store features\n",
    "    result.append(get_store_visitor_feat(label, key, 56))          # store features\n",
    "    result.append(get_store_visitor_feat(label, key, 28))          # store features\n",
    "    result.append(get_store_visitor_feat(label, key, 14))          # store features\n",
    "    result.append(get_store_exp_visitor_feat(label, key, 1000))    # store exp features\n",
    "    result.append(get_store_week_feat(label, key, 1000))           # store dow features\n",
    "    result.append(get_store_week_feat(label, key, 56))             # store dow features\n",
    "    result.append(get_store_week_feat(label, key, 28))             # store dow features\n",
    "    result.append(get_store_week_feat(label, key, 14))             # store dow features\n",
    "    result.append(get_store_week_diff_feat(label, key, 58))       # store dow diff features\n",
    "    result.append(get_store_week_diff_feat(label, key, 1000))      # store dow diff features\n",
    "    result.append(get_store_all_week_feat(label, key, 1000))       # store all week feat\n",
    "    result.append(get_store_week_exp_feat(label, key, 1000))       # store dow exp feat\n",
    "    result.append(get_store_holiday_feat(label, key, 1000))        # store holiday feat\n",
    "\n",
    "    result.append(get_genre_visitor_feat(label, key, 1000))         # genre feature\n",
    "    result.append(get_genre_visitor_feat(label, key, 56))           # genre feature\n",
    "    result.append(get_genre_visitor_feat(label, key, 28))           # genre feature\n",
    "    result.append(get_genre_exp_visitor_feat(label, key, 1000))     # genre feature\n",
    "    result.append(get_genre_week_feat(label, key, 1000))            # genre dow feature\n",
    "    result.append(get_genre_week_feat(label, key, 56))              # genre dow feature\n",
    "    result.append(get_genre_week_feat(label, key, 28))              # genre dow feature\n",
    "    result.append(get_genre_week_exp_feat(label, key, 1000))        # genre dow exp feature\n",
    "\n",
    "    result.append(get_reserve_feat(label,key))                      # air_reserve\n",
    "    result.append(get_first_last_time(label,key,1000))             # first time and last time\n",
    "\n",
    "    result.append(label)\n",
    "\n",
    "    print('merge...')\n",
    "    result = concat(result)\n",
    "\n",
    "    result = second_feat(result)\n",
    "\n",
    "    print('data shape：{}'.format(result.shape))\n",
    "    print('spending {}s'.format(time.time() - t0))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-03-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data key：('2017-03-12', 39)\n",
      "add label\n",
      "make features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  del sys.path[0]\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge...\n",
      "data shape：(27728, 186)\n",
      "spending 79.18613910675049s\n",
      "data key：('2017-03-05', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27705, 186)\n",
      "spending 81.14532995223999s\n",
      "data key：('2017-02-26', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27745, 186)\n",
      "spending 83.7630226612091s\n",
      "data key：('2017-02-19', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27696, 186)\n",
      "spending 79.07429885864258s\n",
      "data key：('2017-02-12', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27596, 186)\n",
      "spending 80.3424620628357s\n",
      "data key：('2017-02-05', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27561, 186)\n",
      "spending 75.00303483009338s\n",
      "data key：('2017-01-29', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27511, 186)\n",
      "spending 75.11559128761292s\n",
      "data key：('2017-01-22', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27474, 186)\n",
      "spending 73.7740409374237s\n",
      "data key：('2017-01-15', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27389, 186)\n",
      "spending 65.32996392250061s\n",
      "data key：('2017-01-08', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27201, 186)\n",
      "spending 66.42059421539307s\n",
      "data key：('2017-01-01', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(25360, 186)\n",
      "spending 69.62977409362793s\n",
      "data key：('2016-12-25', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(24721, 186)\n",
      "spending 66.20792484283447s\n",
      "data key：('2016-12-18', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(24712, 186)\n",
      "spending 59.232364892959595s\n",
      "data key：('2016-12-11', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(24761, 186)\n",
      "spending 57.58559703826904s\n",
      "data key：('2016-12-04', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(24817, 186)\n",
      "spending 57.635947942733765s\n",
      "data key：('2016-11-27', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(25184, 186)\n",
      "spending 54.89012598991394s\n",
      "data key：('2016-11-20', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27458, 186)\n",
      "spending 53.291505098342896s\n",
      "data key：('2016-11-13', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27418, 186)\n",
      "spending 51.82237100601196s\n",
      "data key：('2016-11-06', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27251, 186)\n",
      "spending 50.374825954437256s\n",
      "data key：('2016-10-30', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27116, 186)\n",
      "spending 48.57481288909912s\n",
      "data key：('2016-10-23', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27085, 186)\n",
      "spending 47.160977840423584s\n",
      "data key：('2016-10-16', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27093, 186)\n",
      "spending 46.03249216079712s\n",
      "data key：('2016-10-09', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26987, 186)\n",
      "spending 44.65361499786377s\n",
      "data key：('2016-10-02', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26949, 186)\n",
      "spending 42.75585198402405s\n",
      "data key：('2016-09-25', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(27032, 186)\n",
      "spending 41.47187423706055s\n",
      "data key：('2016-09-18', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26776, 184)\n",
      "spending 39.9849328994751s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data key：('2016-09-11', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26767, 186)\n",
      "spending 38.49063301086426s\n",
      "data key：('2016-09-04', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26707, 186)\n",
      "spending 38.93418598175049s\n",
      "data key：('2016-08-28', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26806, 186)\n",
      "spending 36.33412504196167s\n",
      "data key：('2016-08-21', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26698, 186)\n",
      "spending 34.55828785896301s\n",
      "data key：('2016-08-14', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26261, 186)\n",
      "spending 33.20579195022583s\n",
      "data key：('2016-08-07', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26168, 186)\n",
      "spending 31.792171001434326s\n",
      "data key：('2016-07-31', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26106, 184)\n",
      "spending 30.364362001419067s\n",
      "data key：('2016-07-24', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26147, 186)\n",
      "spending 28.827205181121826s\n",
      "data key：('2016-07-17', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26049, 186)\n",
      "spending 27.290796041488647s\n",
      "data key：('2016-07-10', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26162, 186)\n",
      "spending 25.734857082366943s\n",
      "data key：('2016-07-03', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(26806, 186)\n",
      "spending 23.130287170410156s\n",
      "data key：('2016-06-26', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(24771, 186)\n",
      "spending 21.053617000579834s\n",
      "data key：('2016-06-19', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(21834, 186)\n",
      "spending 20.063705921173096s\n",
      "data key：('2016-06-12', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(18893, 186)\n",
      "spending 19.436776876449585s\n",
      "data key：('2016-06-05', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(16061, 186)\n",
      "spending 17.847792863845825s\n",
      "data key：('2016-05-29', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(13094, 186)\n",
      "spending 17.164806842803955s\n",
      "data key：('2016-05-22', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10600, 186)\n",
      "spending 16.17361617088318s\n",
      "data key：('2016-05-15', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10548, 186)\n",
      "spending 15.732324838638306s\n",
      "data key：('2016-05-08', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10499, 186)\n",
      "spending 15.05476713180542s\n",
      "data key：('2016-05-01', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10338, 186)\n",
      "spending 14.595464944839478s\n",
      "data key：('2016-04-24', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10330, 186)\n",
      "spending 13.91106390953064s\n",
      "data key：('2016-04-17', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10300, 186)\n",
      "spending 14.625708103179932s\n",
      "data key：('2016-04-10', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10282, 186)\n",
      "spending 14.078813076019287s\n",
      "data key：('2016-04-03', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10258, 186)\n",
      "spending 12.794517993927002s\n",
      "data key：('2016-03-27', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10346, 186)\n",
      "spending 12.544023990631104s\n",
      "data key：('2016-03-20', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10382, 186)\n",
      "spending 11.274123907089233s\n",
      "data key：('2016-03-13', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10342, 186)\n",
      "spending 10.511705875396729s\n",
      "data key：('2016-03-06', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10314, 186)\n",
      "spending 10.69091796875s\n",
      "data key：('2016-02-28', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10318, 186)\n",
      "spending 9.845231771469116s\n",
      "data key：('2016-02-21', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10302, 186)\n",
      "spending 8.954113960266113s\n",
      "data key：('2016-02-14', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10242, 186)\n",
      "spending 8.468735933303833s\n",
      "data key：('2016-02-07', 39)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10243, 186)\n",
      "spending 7.648223161697388s\n"
     ]
    }
   ],
   "source": [
    "for i in range(58):\n",
    "    train_feat_sub = make_feats(date_add_days(start_date, i*(-7)), 39)\n",
    "    train_feat = pd.concat([train_feat, train_feat_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data key：('2017-03-19', 35)\n",
      "add label\n",
      "make features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  del sys.path[0]\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge...\n",
      "data shape：(24969, 186)\n",
      "spending 79.93775534629822s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data key：('2017-03-26', 28)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(20049, 186)\n",
      "spending 80.9590117931366s\n",
      "data key：('2017-04-02', 21)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(14999, 186)\n",
      "spending 81.22624182701111s\n",
      "data key：('2017-04-09', 14)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(10008, 186)\n",
      "spending 86.13845014572144s\n",
      "data key：('2017-04-16', 7)\n",
      "add label\n",
      "make features...\n",
      "merge...\n",
      "data shape：(5012, 186)\n",
      "spending 88.1272759437561s\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):\n",
    "    train_feat_sub = make_feats(date_add_days(start_date, i*7), 42-i*7)\n",
    "    train_feat = pd.concat([train_feat, train_feat_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data key：('2017-04-23', 39)\n",
      "add label\n",
      "make features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  del sys.path[0]\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  app.launch_new_instance()\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "/anaconda3/envs/supply_chain_AI/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge...\n",
      "data shape：(32019, 186)\n",
      "spending 87.44816899299622s\n"
     ]
    }
   ],
   "source": [
    "test_feat = make_feats(date_add_days(start_date, 42), 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [f for f in test_feat.columns if f not in ['id', 'store_id', 'visit_date', 'end_date', 'air_area_name', 'visitors', 'month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': .02,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'sub_feature': .7,\n",
    "    'num_leaves': 60,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_feat[predictors], train_feat['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_test = lgb.Dataset(test_feat[predictors], test_feat['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(params, lgb_train, 2300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbm.predict(test_feat[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1021.3801219463348 secondes\n"
     ]
    }
   ],
   "source": [
    "print('Training time: {} secondes'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = pd.DataFrame({'id': test_feat.store_id + '_' + test_feat.visit_date, 'visitors': np.expm1(pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm = submission[['id']].merge(subm, on='id', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv(r'..\\sub{}.csv'.format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
