{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T10:27:04.982905Z",
     "start_time": "2020-03-18T10:27:01.164271Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从区块构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从`tf.keras.Model` 继承 `__init__`和`call`函数。它们分别用于创建模型参数和定义正向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T09:49:30.974899Z",
     "start_time": "2020-03-17T09:49:30.956730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.3517177 ,  0.0590828 , -0.09553804,  0.18189082,  0.10262021,\n",
       "         0.1591081 ,  0.04742083,  0.04850521, -0.0761077 , -0.05269895],\n",
       "       [-0.57858044,  0.25556022, -0.15854385, -0.09426881,  0.12265214,\n",
       "         0.30309367,  0.1856965 ,  0.15669292, -0.13691807, -0.14801069]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建正向传播模型\n",
    "class MLP(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.dense1 = keras.layers.Dense(units=256, activation=tf.nn.relu)\n",
    "        self.dense2 = keras.layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "# 一次正向传播\n",
    "X = tf.random.uniform((2,20))\n",
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上，我们常用的`Sequential`也继承自`tf.keras.Model`。当模型进行正向传播为**简单串联各个层**的计算时，可以通过`Sequential`来更加简单的定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T10:19:27.077836Z",
     "start_time": "2020-03-17T10:19:27.065106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.03315611,  0.3800161 ,  0.23285574,  0.02806905, -0.47320196,\n",
       "         0.35398674, -0.21407685,  0.15584847, -0.27790308,  0.06921495],\n",
       "       [-0.04699008,  0.2853636 ,  0.03808613, -0.1333533 , -0.4015093 ,\n",
       "         0.12817937,  0.0796181 ,  0.14587305, -0.09163154,  0.20914048]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接通过list来构建模型\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T09:46:31.226686Z",
     "start_time": "2020-03-17T09:46:31.214143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.3122393 ,  0.05919163,  0.03653248, -0.08400317, -0.22641888,\n",
       "         0.00232723,  0.21166524, -0.07668218,  0.09955931,  0.0278854 ],\n",
       "       [ 0.21390367, -0.06434882,  0.04908498,  0.01998814, -0.2421408 ,\n",
       "        -0.21148819,  0.27529937,  0.01524206, -0.09090518,  0.05558806]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过add来构建模型\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(10))\n",
    "\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建复杂模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然`Sequential`可以使构建模型更加简单且不需要定义`call`函数，但是直接继承`tf.keras.Model`类可以极大扩展模型构造的灵活性。下例中，通过`constant`函数创建训练中不被迭代的参数，即常数参数。在正向传播中，除了使用创建的常数参数外，我们还是用了`tensor`的函数和Python控制流，并多次调用相同的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T09:49:22.024854Z",
     "start_time": "2020-03-17T09:49:22.006270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.5308247>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FancyMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.rand_weight = tf.constant(\n",
    "            tf.random.uniform((20,20)))\n",
    "        self.dense = tf.keras.layers.Dense(units=20, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, inputs):         \n",
    "        x = self.flatten(inputs)   \n",
    "        x = tf.nn.relu(tf.matmul(x, self.rand_weight) + 1)\n",
    "        x = self.dense(x)    \n",
    "        while tf.norm(x) > 1:\n",
    "            x /= 2\n",
    "        if tf.norm(x) < 0.8:\n",
    "            x *= 10\n",
    "        return tf.reduce_sum(x)\n",
    "\n",
    "net = FancyMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为`FancyMLP`和`Sequential`都是`tf.keras.Model`的子类，所以可以嵌套调用它们"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T09:50:13.862449Z",
     "start_time": "2020-03-17T09:50:13.833324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=19.843418>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = tf.keras.Sequential()\n",
    "        self.net.add(tf.keras.layers.Flatten())\n",
    "        self.net.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "        self.net.add(tf.keras.layers.Dense(32, activation=tf.nn.relu))\n",
    "        self.dense = tf.keras.layers.Dense(units=16, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, inputs):         \n",
    "        return self.dense(self.net(inputs))\n",
    "\n",
    "net = tf.keras.Sequential()\n",
    "net.add(NestMLP())\n",
    "net.add(tf.keras.layers.Dense(20))\n",
    "net.add(FancyMLP())\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T09:58:10.058267Z",
     "start_time": "2020-03-17T09:58:10.053463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "nest_mlp (NestMLP)           multiple                  3952      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             multiple                  340       \n",
      "_________________________________________________________________\n",
      "fancy_mlp_14 (FancyMLP)      multiple                  420       \n",
      "=================================================================\n",
      "Total params: 4,712\n",
      "Trainable params: 4,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型参数的访问、初始化和共享"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T08:58:52.645893Z",
     "start_time": "2020-03-18T08:58:52.628657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[ 0.03510882, -0.34613597, -0.02393222, -0.18034738, -0.05238268,\n",
       "        -0.08591746,  0.01697223,  0.1875126 ,  0.42745113,  0.31601268],\n",
       "       [ 0.21769872, -0.36894047, -0.10778795, -0.19691208, -0.07622939,\n",
       "         0.16868882,  0.0686077 ,  0.12315129,  0.1612009 ,  0.1531213 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential()\n",
    "net.add(tf.keras.layers.Flatten())\n",
    "net.add(tf.keras.layers.Dense(256,activation=tf.nn.relu))\n",
    "net.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "X = tf.random.uniform((2,20))\n",
    "Y = net(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 访问模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`Sequential`构造的神经网络，可以通过`weights`属性来访问网络任一层的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T09:19:32.238309Z",
     "start_time": "2020-03-18T09:19:32.231081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'sequential_54/dense_134/kernel:0' shape=(20, 256) dtype=float32, numpy=\n",
       " array([[-0.03383882, -0.11707048,  0.10972074, ...,  0.08872013,\n",
       "          0.06855111,  0.02397333],\n",
       "        [ 0.08151212,  0.00056681,  0.03013374, ..., -0.00486116,\n",
       "          0.03044017,  0.06502134],\n",
       "        [ 0.132911  ,  0.12222865,  0.09149063, ..., -0.13583285,\n",
       "          0.13097805, -0.14202355],\n",
       "        ...,\n",
       "        [-0.14262432, -0.07902815, -0.00359689, ...,  0.07753824,\n",
       "         -0.05405951, -0.10552894],\n",
       "        [-0.09352137, -0.01143943,  0.12965965, ..., -0.12315992,\n",
       "          0.10722223,  0.05119947],\n",
       "        [ 0.13653904, -0.08938001,  0.02308467, ..., -0.04827231,\n",
       "          0.11051106,  0.05444454]], dtype=float32)>,\n",
       " <tf.Variable 'sequential_54/dense_134/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.], dtype=float32)>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten层无weights和bias被无视\n",
    "# 一个Dense层会产生两个weights，其中[0]为w, [1]为b\n",
    "net.weights[0], net.weights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的默认初始化方法为: 权重参数元素为[-0.07, 0.07]之间均匀分布的随机数, 偏差则为0。通常我们需要使用其他方法来初始化权重，在下面的例子中，将权重参数初始化为均值为0，标准差为0.01的正态分布随机数，偏差为0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T09:26:41.185406Z",
     "start_time": "2020-03-18T09:26:41.166459Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00909971,  0.00596697, -0.00332779,  0.0149344 , -0.00717133,\n",
       "         -0.0014989 , -0.0087957 ,  0.00282516, -0.00195604, -0.00067179],\n",
       "        [ 0.00490627, -0.01633284,  0.00755273,  0.00136864, -0.02045935,\n",
       "         -0.01924302, -0.01074835, -0.00238334, -0.00282798, -0.01072354],\n",
       "        [-0.00421563, -0.0090111 ,  0.02130167, -0.01302595,  0.00599386,\n",
       "         -0.01292618,  0.01114051, -0.01639823,  0.00310355,  0.01305074],\n",
       "        [ 0.00324933,  0.01948626, -0.02190285,  0.00387663, -0.01059838,\n",
       "          0.02322861,  0.01128075,  0.02057246,  0.00265373, -0.01068667],\n",
       "        [-0.00877597, -0.00808634,  0.00227806, -0.00323111, -0.00474815,\n",
       "         -0.02480922,  0.00621112, -0.0022819 , -0.00989668, -0.01789486],\n",
       "        [ 0.00881773, -0.00289748, -0.004485  ,  0.00593094, -0.01509368,\n",
       "          0.00144251,  0.00610703,  0.02330093,  0.00999746, -0.00072805],\n",
       "        [ 0.00837816,  0.0138937 , -0.00884771, -0.00474632, -0.00267756,\n",
       "          0.00205341, -0.02439167, -0.01047149,  0.00650615, -0.0008819 ],\n",
       "        [-0.02130503, -0.00558904, -0.00773592,  0.00708538,  0.00909705,\n",
       "          0.00348862, -0.01621456, -0.0121804 ,  0.00757219, -0.00227624],\n",
       "        [-0.00331888,  0.00026989, -0.00716165, -0.01791381, -0.01136041,\n",
       "          0.02422766,  0.0085435 , -0.01148283,  0.0039684 , -0.00261161],\n",
       "        [-0.01317908,  0.01139958,  0.00844003, -0.01235665,  0.00372866,\n",
       "          0.01633544, -0.00104884,  0.00587575, -0.01029281,  0.00220148],\n",
       "        [-0.01037773,  0.00696713,  0.00515878, -0.01294637, -0.01141919,\n",
       "         -0.00973217, -0.00853849, -0.00025664,  0.00644591, -0.01162126],\n",
       "        [ 0.0009622 ,  0.0063417 ,  0.00779757,  0.01316756,  0.01810629,\n",
       "         -0.00945975, -0.00847495,  0.00451313, -0.00469926,  0.01201725],\n",
       "        [-0.00920867, -0.01087016, -0.013814  ,  0.00826801, -0.00363457,\n",
       "          0.01791816,  0.01265273, -0.00996236,  0.0128295 ,  0.00715792],\n",
       "        [-0.00206756,  0.01135624,  0.00185417, -0.00492527,  0.01272352,\n",
       "          0.00913357, -0.00769917, -0.03018334, -0.00107997, -0.00366633],\n",
       "        [ 0.01027638, -0.00564079,  0.01014407,  0.00552502,  0.00582367,\n",
       "         -0.00640354,  0.00194443, -0.00915793,  0.00454342, -0.00482852],\n",
       "        [-0.00576111,  0.00751735, -0.00103822, -0.01549897, -0.0109504 ,\n",
       "          0.01271524,  0.01711985, -0.01393069, -0.00184926,  0.00183724],\n",
       "        [-0.00693432,  0.01422831, -0.00108688,  0.00240108,  0.00948192,\n",
       "         -0.00310708,  0.00228963,  0.0096226 ,  0.01857045, -0.00126992],\n",
       "        [ 0.00269975,  0.00768398,  0.01505609, -0.00119786, -0.0013918 ,\n",
       "         -0.00841364, -0.00143153, -0.00261627, -0.00127014,  0.00037756],\n",
       "        [-0.01103437, -0.00825497,  0.01078275,  0.00369258,  0.00699734,\n",
       "          0.01273305, -0.00414398, -0.00250013, -0.00730607, -0.00527431],\n",
       "        [ 0.00049223, -0.00158363,  0.00635782, -0.00558007, -0.00165608,\n",
       "          0.00562294,  0.00951721,  0.01147476, -0.00769456,  0.01208705]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.00078313],\n",
       "        [ 0.01711081],\n",
       "        [ 0.00062877],\n",
       "        [-0.00573147],\n",
       "        [-0.00874658],\n",
       "        [ 0.01423447],\n",
       "        [ 0.00543927],\n",
       "        [ 0.01173418],\n",
       "        [-0.01833431],\n",
       "        [-0.0013559 ]], dtype=float32),\n",
       " array([1.], dtype=float32)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Linear(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.d1 = tf.keras.layers.Dense(\n",
    "            units=10,\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.01),  # weight\n",
    "            bias_initializer=tf.zeros_initializer()   # bias\n",
    "        )\n",
    "        self.d2 = tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.random_normal_initializer(mean=0, stddev=0.01),\n",
    "            bias_initializer=tf.ones_initializer()\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        output = self.d1(input)\n",
    "        output = self.d2(output)\n",
    "        return output\n",
    "\n",
    "net = Linear()\n",
    "net(X)\n",
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用`tf.keras.initializers` 来自定义初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T09:42:33.104117Z",
     "start_time": "2020-03-18T09:42:33.093742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_55/dense_138/kernel:0' shape=(20, 64) dtype=float32, numpy=\n",
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init():\n",
    "    return tf.keras.initializers.Ones()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, kernel_initializer=my_init()))\n",
    "\n",
    "Y = model(X)\n",
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 延后初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在使用`Sequential`里的`layers`进行创建全连接层的时候，都没有指定输入的个数，由于输入的个数未知，因此该层的w和b也没有办法进行初始化，只有在数据传入网络之后，才会初始化其各层的w和b，这叫做延后初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:18:23.295966Z",
     "start_time": "2020-03-19T08:18:23.289684Z"
    }
   },
   "outputs": [],
   "source": [
    "net = tf.keras.models.Sequential()\n",
    "net.add(tf.keras.layers.Flatten())\n",
    "net.add(tf.keras.layers.Dense(256,activation=tf.nn.relu))\n",
    "net.add(tf.keras.layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:19:20.908309Z",
     "start_time": "2020-03-19T08:19:20.905031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The w of first layer has not been created\n"
     ]
    }
   ],
   "source": [
    "# 第一层网络的w还没有初始化，因此报错\n",
    "\n",
    "try:\n",
    "    net.weights[0]\n",
    "except:\n",
    "    print('The w of first layer has not been created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:19:44.833712Z",
     "start_time": "2020-03-19T08:19:44.820608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'sequential_1/dense_2/kernel:0' shape=(20, 256) dtype=float32, numpy=\n",
       "array([[-0.07148068, -0.1116434 ,  0.13821396, ...,  0.14516154,\n",
       "        -0.0500281 ,  0.12749329],\n",
       "       [ 0.05667473, -0.07406509,  0.03059828, ...,  0.02128822,\n",
       "         0.07427762,  0.13693061],\n",
       "       [ 0.05781633,  0.03457713, -0.0407213 , ...,  0.00135897,\n",
       "        -0.04260268, -0.06990696],\n",
       "       ...,\n",
       "       [-0.12363131,  0.07524391, -0.04777505, ...,  0.11447403,\n",
       "        -0.12888934, -0.08623327],\n",
       "       [ 0.09619942,  0.08833931, -0.0370017 , ..., -0.07345831,\n",
       "         0.00284949,  0.05666068],\n",
       "       [ 0.13059112,  0.12397876, -0.13316517, ...,  0.03502269,\n",
       "        -0.14035225, -0.1291043 ]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在传入数据后，每一层都有了参数\n",
    "\n",
    "X = tf.random.uniform((2,20))\n",
    "Y = net(X)\n",
    "\n",
    "net.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras`虽然提供了大量常用的层，但是有时候我们仍希望自定义层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义无参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下例中，通过继承`tf.keras.layers.Layer`自定义了一个将输入减掉均值后输出的层。并将该层的计算定义在了`call`函数里面。这个层里面不含参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:33:05.922107Z",
     "start_time": "2020-03-19T08:33:05.918616Z"
    }
   },
   "outputs": [],
   "source": [
    "class CenteredLayer(tf.keras.layers.Layer):\n",
    "    def __inif__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return inputs - tf.reduce_mean(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:33:06.096302Z",
     "start_time": "2020-03-19T08:33:06.085240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 20), dtype=float32, numpy=\n",
       "array([[-0.20958811,  0.20888385,  0.8755732 , -0.29745674, -0.02969303,\n",
       "         0.10262606,  1.1162755 ,  0.3695641 ,  0.31335768, -0.70059276,\n",
       "        -0.14199486, -0.16570246,  0.03128872, -0.10945373, -0.6193166 ,\n",
       "        -0.24931586,  0.1426819 ,  0.14857855,  0.06305855,  0.75794154],\n",
       "       [-0.42829385,  0.2524372 ,  1.3564847 , -0.21308675, -0.4226271 ,\n",
       "        -0.11136381,  0.35428724, -0.02224728,  0.9663147 , -0.3997038 ,\n",
       "        -0.38516703, -0.58401126, -0.45115656, -0.71701694, -0.9077915 ,\n",
       "        -0.24290758,  0.42526743, -0.12259867, -0.5712693 ,  0.6177351 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential()\n",
    "net.add(tf.keras.layers.Flatten())\n",
    "net.add(tf.keras.layers.Dense(20))\n",
    "net.add(CenteredLayer())\n",
    "\n",
    "Y = net(X)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义有参数的层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build一般用来往Layer中添加变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:36:43.763457Z",
     "start_time": "2020-03-19T08:36:43.758029Z"
    }
   },
   "outputs": [],
   "source": [
    "class myDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='w',\n",
    "                                 shape=[input_shape[-1], self.units],\n",
    "                                 initializer=tf.random_normal_initializer())\n",
    "        self.b = self.add_weight(name='b',\n",
    "                                 shape=[1, self.units], \n",
    "                                 initializer=tf.zeros_initializer())\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:38:23.343786Z",
     "start_time": "2020-03-19T08:38:23.332024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-0.00166104],\n",
       "       [-0.01320496]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = tf.keras.models.Sequential()\n",
    "net.add(myDense(8))\n",
    "net.add(myDense(1))\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取和储存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取储存NDarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建了一个`tensor`, 使用`np.save`进行保存，然后使用`np.load`读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:58:58.710094Z",
     "start_time": "2020-03-19T08:58:58.703604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.ones(3)\n",
    "np.save('files/class5_4.1 - x.npy', x)\n",
    "\n",
    "x2 = np.load('files/class5_4.1 - x.npy')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以储存一列`tensor`， 然后再将其读回内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:58:59.013332Z",
     "start_time": "2020-03-19T08:58:59.006656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.zeros(4)\n",
    "np.save('files/class5_4.1 - xy.npy', [x,y])\n",
    "\n",
    "x2, y2 = np.load('files/class5_4.1 - xy.npy', allow_pickle=True)\n",
    "(x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以储存并读取一个从字符串映射到`tensor`的字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T08:58:59.274537Z",
     "start_time": "2020-03-19T08:58:59.267804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'x': <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>, 'y': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'x':x, 'y':y}\n",
    "np.save('files/class5_4.1 - mydict.npy', mydict)\n",
    "\n",
    "mydict2 = np.load('files/class5_4.1 - mydict.npy', allow_pickle=True)\n",
    "mydict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取储存模型参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新建一个模型并进行初始化参数，然后使用`save_weights`将其储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:00:02.008695Z",
     "start_time": "2020-03-19T09:00:01.991140Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.random.normal((2,20))\n",
    "net1 = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "Y1 = net1(X)\n",
    "Y1\n",
    "\n",
    "net1.save_weights('files/class5_4.2 - saved_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建一个与net1一致的NN，将其初始化之后，使用`load_weights`读取net1的权重参数，然后进行一次正向传播。Y1与Y2的值一致，表示net1与net2的权重参数一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T09:00:15.826989Z",
     "start_time": "2020-03-19T09:00:15.807212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "net2(X)\n",
    "net2.load_weights('files/class5_4.2 - saved_model.h5')\n",
    "Y2 = net2(X)\n",
    "Y2 == Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因该部分需要GPU，而MAC环境只有CPU。该部分内容略去，若要理解则自行去书4.6看代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重点总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Layer`与`tf.keras.Model`的类同与区别\n",
    "- `tf.keras.Model`可以使用`.fit()`/`.evaluate()`/`.predict()`等。 而在`tf.keras.layers.Layer`不可以使用上述方法\n",
    "- 一般而言，在构建层/块的时候, 倾向于使用`tf.keras.layers.Layer` (如Inception Block /ResNet Block /Convolutional Layer 等)\n",
    "- 一般而言，在构建网络的时候, 倾向于使用`tf.keras.Model` (如自己构建的DL_Model/NN等)\n",
    "- 他们两个其实内在的参数使用是非常类似的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`tf.keras.layers.Layer`与`tf.keras.Model`中, 使用`super(class_name, self).__init__()`来继承上述类的属性和方法\n",
    "- `__init__`中, 里面含有从类中继承来的属性, 并且我们可以在这里面定义自己类的对象\n",
    "- `build`中, 用于定义 该层/网络 中额外的 参数(包括超参数/固定参数等)\n",
    "- `call`中, 用于定义该层/网络中的正向传播逻辑 \n",
    "\n",
    "例子: class7_5.2/ class8_1.2 等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
