{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在3.DL基础里面我们构造了一个含单隐藏层的MLP对Fashion-MNIST中的图像进行分裂。每张图像的高和宽为28像素。我们将图像中的像素Flatten，得到长度为784的向量，并输入FC层中。然而这种方法是有局限性的:\n",
    "1. 图像在同一列邻近的像素在向量中会相聚较远，构成的模式很难被模型识别\n",
    "2. 对于大尺寸的输入图像，使用FC层很容易导致模型较大。假设输入的是高和宽均为1000像素的彩色(RGB)图片。即使全连接层的输出仍为256个，但是该层的权重参数为1000x1000x3x256，大约为3G的内存。这会带来过于复杂的模型和过高的储存开销。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而卷积层解决了这两个问题。一方面，卷积层保留输入数据的形状，使图像的像素在高和宽两个方向上的相关性均能被有效识别；另一方面，军基层通过滑动窗口将统一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T08:08:38.944166Z",
     "start_time": "2020-03-25T08:08:38.937607Z"
    }
   },
   "source": [
    "LeNet分为卷积层块和全连接层块两个部分。下面我们分别介绍这两个模块。\n",
    "\n",
    "卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用$5\\times 5$的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为$2\\times 2$，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。\n",
    "\n",
    "卷积层块的输出形状为(批量大小, 高, 宽, 通道)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/class7_1.1.png\" style=\"zoom:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结:（Conv+MaxPool)\\*2 + FC\\*3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxPool2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T11:02:41.386901Z",
     "start_time": "2020-04-01T11:02:38.552394Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:21:59.748080Z",
     "start_time": "2020-03-30T09:21:59.684765Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_171 (Conv2D)          (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建网络\n",
    "LeNet = tf.keras.Sequential([\n",
    "    Conv2D(filters=6, kernel_size=(5,5), activation='sigmoid', input_shape=(28,28,1)),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    Conv2D(filters=16, kernel_size=(5,5), activation='sigmoid'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(120, activation='sigmoid'),\n",
    "    Dense(84, activation='sigmoid'),\n",
    "    Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "LeNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:22:01.702493Z",
     "start_time": "2020-03-30T09:21:59.977424Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取数据\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# 修改数据shape (channel=1)\n",
    "train_images = tf.reshape(train_images, (train_images.shape[0],train_images.shape[1],train_images.shape[2], 1))\n",
    "test_images = tf.reshape(test_images, (test_images.shape[0],test_images.shape[1],test_images.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:22:45.767554Z",
     "start_time": "2020-03-30T09:22:01.734038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 9s 169us/sample - loss: 1.2935 - accuracy: 0.4944 - val_loss: 0.6593 - val_accuracy: 0.7448\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 9s 169us/sample - loss: 0.6450 - accuracy: 0.7501 - val_loss: 0.6684 - val_accuracy: 0.7482\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 9s 165us/sample - loss: 0.5806 - accuracy: 0.7752 - val_loss: 0.6273 - val_accuracy: 0.7697\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 8s 155us/sample - loss: 0.5532 - accuracy: 0.7881 - val_loss: 0.5203 - val_accuracy: 0.8090\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 8s 156us/sample - loss: 0.5090 - accuracy: 0.8065 - val_loss: 0.4831 - val_accuracy: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdbe8a8ec50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "LeNet.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.9, momentum=0.0, nesterov=False),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "LeNet.fit(train_images, train_labels, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:22:46.496250Z",
     "start_time": "2020-03-30T09:22:45.792073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.5056 - accuracy: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5056428252696991, 0.8125]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试集检验\n",
    "LeNet.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比于LeNet，AlexNet包含8层转换，即5层卷积、2层FC隐层、1层FC输出层。\n",
    "\n",
    "第一层为卷积且shape=(11,11), 因为ImageNet的图像像素比MNIST大10倍以上，所以使用更大的卷积层来捕获物体。第二层中的卷积窗口为(5,5)，之后的卷积全使用(3,3)。此外，第一、第二、第五卷积层之后都是用了shape=(3,3) & strides=(2,2)的最大池化层。并且其中使用的channels数量为LeNet中的数十倍。\n",
    "\n",
    "在最后一个卷积层之后是两个FC层。AlexNet中的所有激活函数全部为ReLU。\n",
    "\n",
    "网络中使用了DropOut来控制FC层中的模型复杂度。\n",
    "\n",
    "AlexNet中引入了大量的图像augment，从而进一步扩大数据集来缓解过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/class7_2.1.png\" style=\"zoom:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结: (Conv+MaxPool)\\*2 + (Conv\\*3 + MaxPool) + (FC + DropOut)\\*2 + FC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:23:26.457721Z",
     "start_time": "2020-03-30T09:23:26.455007Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:23:26.965592Z",
     "start_time": "2020-03-30T09:23:26.654390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_173 (Conv2D)          (None, 54, 54, 96)        11712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建网络\n",
    "\n",
    "AlexNet = tf.keras.models.Sequential([\n",
    "    Conv2D(filters=96,kernel_size=11,strides=4,activation='relu', input_shape=(224,224,1)),\n",
    "    MaxPool2D(pool_size=3, strides=2),\n",
    "    Conv2D(filters=256,kernel_size=5,padding='same',activation='relu'),\n",
    "    MaxPool2D(pool_size=3, strides=2),\n",
    "    Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "    Conv2D(filters=384,kernel_size=3,padding='same',activation='relu'),\n",
    "    Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'),\n",
    "    MaxPool2D(pool_size=3, strides=2),\n",
    "    Flatten(),\n",
    "    Dense(4096,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10,activation='sigmoid')\n",
    "])\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:23:49.982817Z",
     "start_time": "2020-03-30T09:23:26.997360Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取处理后数据\n",
    "\n",
    "def get_data():\n",
    "    # 获取数据\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    # 修改数据shape (channel=1)\n",
    "    train_images = tf.reshape(train_images, (train_images.shape[0],train_images.shape[1],train_images.shape[2], 1))\n",
    "    test_images = tf.reshape(test_images, (test_images.shape[0],test_images.shape[1],test_images.shape[2], 1))\n",
    "\n",
    "    # pad图像shape至244,244\n",
    "    train_images = tf.image.resize_with_pad(train_images, 224, 224, )\n",
    "    test_images = tf.image.resize_with_pad(test_images, 224, 224, )\n",
    "    \n",
    "    # 标准化图像\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:24:00.689096Z",
     "start_time": "2020-03-30T09:23:50.021947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 - 10s - loss: 0.3125 - accuracy: 0.8845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.31246792006492613, 0.8845]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练\n",
    "\n",
    "AlexNet.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# AlexNet.fit(x=train_images,\n",
    "#             y=train_labels,\n",
    "#             batch_size=128,\n",
    "#             epochs=5,\n",
    "#             verbose=2)\n",
    "\n",
    "# 因为CPU训练要很久，所以用GPU训练完了把weights拿过来\n",
    "AlexNet.load_weights('files/class7_2_weights.h5')\n",
    "\n",
    "# 查看test集前2000的准确率\n",
    "AlexNet.evaluate(test_images[:2000], test_labels[:2000], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG名字来源于其论文作者所在实验室为Visual Geometry Group。VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结: VGG_block\\*n + (FC + DropOut)\\*2 + FC**\n",
    "\n",
    "**VGG_block = Conv\\*n + MaxPool**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:25:26.445865Z",
     "start_time": "2020-03-30T09:25:26.442951Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T07:51:21.910148Z",
     "start_time": "2020-03-27T07:51:21.904704Z"
    }
   },
   "source": [
    "VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为3×3的卷积层后接上一个步幅为2、窗口形状为2×2的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用`vgg_block`函数来实现这个基础的VGG块，它可以指定卷积层的数量`num_convs`和输出通道数`num_filters`。\n",
    "\n",
    "与AlexNet和LeNet一样，VGG网络由卷积层模块后接全连接层模块构成。卷积层模块串联数个`vgg_block`，其超参数由变量`conv_arch`定义。该变量指定了每个VGG块里卷积层个数和输出通道数。全连接模块则跟AlexNet中的一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:25:27.089222Z",
     "start_time": "2020-03-30T09:25:27.076796Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG块\n",
    "def vgg_block(num_convs, num_filters):\n",
    "    '''\n",
    "    num_convs: 卷积层的个数\n",
    "    filters: 卷积层内filters的数量\n",
    "    '''\n",
    "    blk = tf.keras.models.Sequential()\n",
    "    for _ in range(num_convs):\n",
    "        blk.add(Conv2D(num_filters, kernel_size=3, padding='same', activation='relu'))\n",
    "    \n",
    "    blk.add(MaxPool2D(pool_size=2, strides=2))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "现在我们构造一个VGG网络。它有5个卷积块，前2块使用单卷积层，而后3块使用双卷积层。第一块的输出通道是64，之后每次对输出通道数翻倍，直到变为512。因为这个网络使用了8个卷积层和3个全连接层，所以经常被称为VGG-11。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:25:27.734332Z",
     "start_time": "2020-03-30T09:25:27.712427Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG网络\n",
    "def vgg_net(conv_arch):\n",
    "    net = tf.keras.models.Sequential()\n",
    "    for (num_convs, filters) in conv_arch:\n",
    "        net.add(vgg_block(num_convs, filters))\n",
    "    net.add(tf.keras.models.Sequential([\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='sigmoid')\n",
    "    ]))\n",
    "    return net\n",
    "\n",
    "# 构造网络\n",
    "conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))\n",
    "VGG = vgg_net(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:25:37.736360Z",
     "start_time": "2020-03-30T09:25:37.215605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential_21 output shape:\t (1, 112, 112, 64)\n",
      "sequential_22 output shape:\t (1, 56, 56, 128)\n",
      "sequential_23 output shape:\t (1, 28, 28, 256)\n",
      "sequential_24 output shape:\t (1, 14, 14, 512)\n",
      "sequential_25 output shape:\t (1, 7, 7, 512)\n",
      "sequential_26 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# 构造一个高和宽为244的单通道数据样本观察每一层的形状\n",
    "\n",
    "X = tf.random.uniform((1,224,224,1))\n",
    "for blk in VGG.layers:\n",
    "    X = blk(X)\n",
    "    print(blk.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:26:11.646581Z",
     "start_time": "2020-03-30T09:25:40.548973Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取数据与训练模型\n",
    "\n",
    "def get_data():\n",
    "    # 获取数据\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    # 修改数据shape (channel=1)\n",
    "    train_images = tf.reshape(train_images, (train_images.shape[0],train_images.shape[1],train_images.shape[2], 1))\n",
    "    test_images = tf.reshape(test_images, (test_images.shape[0],test_images.shape[1],test_images.shape[2], 1))\n",
    "\n",
    "    # pad图像shape至244,244\n",
    "    train_images = tf.image.resize_with_pad(train_images, 224, 224, )\n",
    "    test_images = tf.image.resize_with_pad(test_images, 224, 224, )\n",
    "    \n",
    "    # 标准化图像\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:29:34.811328Z",
     "start_time": "2020-03-30T09:28:03.326266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 - 91s - loss: 0.2166 - accuracy: 0.9210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21661576175689698, 0.921]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练网络\n",
    "\n",
    "VGG.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.0, nesterov=False),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# VGG.fit(x=train_images,\n",
    "#         y=train_labels,\n",
    "#         batch_size=128,\n",
    "#         epochs=5,\n",
    "#         verbose=2)\n",
    "\n",
    "# 因为CPU训练要很久，所以用GPU训练完了把weights拿过来\n",
    "VGG.load_weights('files/class7_3_weights.h5')\n",
    "\n",
    "# 查看test集前2000的准确率\n",
    "VGG.evaluate(test_images[:2000], test_labels[:2000], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本part前几节中介绍的LeNet、AlexNet、VGG在设计上的共同之处是: 先以军基层构成的模块充分抽取空间特征，再以全连接层构成的模块来输出分类结果。其中AlexNet和VGG对LeNet的改进主要在与如何对这个两个模块加宽和加深。\n",
    "\n",
    "本节介绍的NiN，它提出了另一个思路，即串联多个由卷积层和FC层构成的小网络来构建一个深层网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**总结: (NiN_block+ MaxPool)\\*n + DropOut + NiN_block + Global_Avg_Pool + Flatten**\n",
    "\n",
    "**NiN_block = Conv + 1x1Conv + 1x1Conv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:29:47.008340Z",
     "start_time": "2020-03-30T09:29:47.005580Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NiN块是NiN中的基础块。卷积层的输入和输出通常是四维数组(样本, 高, 宽, 通道数), 而FC层的输入和输出通常是二维数组(样本, 特征)。如果想在FC层后再接上卷积层，则需要将FC层的输出变化为四维。在class6_4中，介绍过1x1卷积层，可以将其看为FC层。因此NiN中使用1x1卷积层来代替FC层，从而使空间信息能够自然传递到后面的层中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:29:47.617457Z",
     "start_time": "2020-03-30T09:29:47.613265Z"
    }
   },
   "outputs": [],
   "source": [
    "# NiN块\n",
    "def nin_block(num_filters, kernel_size, strides, padding):\n",
    "    blk = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=num_filters, kernel_size=kernel_size, \n",
    "               strides=strides, padding=padding, activation='relu'),\n",
    "        Conv2D(filters=num_filters, kernel_size=1, activation='relu'),\n",
    "        Conv2D(filters=num_filters, kernel_size=1, activation='relu')\n",
    "    ])\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了NiN块之外，NiN去掉了AlexNet最后的三个FC层，取而代之的，NiN使用了输出通道数等于标签类别数的NiN块，然后使用全局平均池化层对每个同道中人的所有元素求平均并直接用于分类。这里的全局平均池化层即窗口形状等于输入空间维形状的平均池化层。NiN的这个设计的好处是可以显著减小模型参数尺寸，从而缓解过拟合。然而，该设计优势会造成获得有效模型的训练时间增加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:29:48.295228Z",
     "start_time": "2020-03-30T09:29:48.274689Z"
    }
   },
   "outputs": [],
   "source": [
    "# NiN网络\n",
    "def nin():\n",
    "    net = tf.keras.models.Sequential([\n",
    "        nin_block(num_filters=96, kernel_size=11, strides=4, padding='valid'),\n",
    "        MaxPool2D(pool_size=3, strides=2),\n",
    "        nin_block(num_filters=256, kernel_size=5, strides=1, padding='same'),\n",
    "        MaxPool2D(pool_size=3, strides=2),\n",
    "        nin_block(num_filters=384, kernel_size=3, strides=1, padding='same'),\n",
    "        MaxPool2D(pool_size=3, strides=2),\n",
    "        Dropout(0.5),\n",
    "        nin_block(num_filters=10, kernel_size=3, strides=1, padding='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Flatten()\n",
    "    ])\n",
    "    return net\n",
    "NiN = nin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:29:48.992057Z",
     "start_time": "2020-03-30T09:29:48.933633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential_27 output shape:\t (1, 54, 54, 96)\n",
      "max_pooling2d_49 output shape:\t (1, 26, 26, 96)\n",
      "sequential_28 output shape:\t (1, 26, 26, 256)\n",
      "max_pooling2d_50 output shape:\t (1, 12, 12, 256)\n",
      "sequential_29 output shape:\t (1, 12, 12, 384)\n",
      "max_pooling2d_51 output shape:\t (1, 5, 5, 384)\n",
      "dropout_4 output shape:\t (1, 5, 5, 384)\n",
      "sequential_30 output shape:\t (1, 5, 5, 10)\n",
      "global_average_pooling2d_3 output shape:\t (1, 10)\n",
      "flatten_3 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# 构造一个高和宽为244的单通道数据样本观察每一层的形状\n",
    "\n",
    "X = tf.random.uniform((1,224,224,1))\n",
    "for blk in NiN.layers:\n",
    "    X = blk(X)\n",
    "    print(blk.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:30:20.523639Z",
     "start_time": "2020-03-30T09:29:49.689458Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取数据与训练模型\n",
    "\n",
    "def get_data():\n",
    "    # 获取数据\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    # 修改数据shape (channel=1)\n",
    "    train_images = tf.reshape(train_images, (train_images.shape[0],train_images.shape[1],train_images.shape[2], 1))\n",
    "    test_images = tf.reshape(test_images, (test_images.shape[0],test_images.shape[1],test_images.shape[2], 1))\n",
    "\n",
    "    # pad图像shape至244,244\n",
    "    train_images = tf.image.resize_with_pad(train_images, 224, 224, )\n",
    "    test_images = tf.image.resize_with_pad(test_images, 224, 224, )\n",
    "    \n",
    "    # 标准化图像\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:31:01.485007Z",
     "start_time": "2020-03-30T09:30:52.851110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 - 9s - loss: 2.5901 - accuracy: 0.1475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5901342182159426, 0.1475]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练网络\n",
    "\n",
    "NiN.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-7),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# NiN.fit(x=train_images,\n",
    "#         y=train_labels,\n",
    "#         batch_size=128,\n",
    "#         epochs=5,\n",
    "#         verbose=2)\n",
    "\n",
    "# 因为CPU训练要很久，所以用GPU训练完了把weights拿过来\n",
    "NiN.load_weights('files/class7_4_weights.h5')\n",
    "\n",
    "# 查看test集前2000的准确率\n",
    "NiN.evaluate(test_images[:2000], test_labels[:2000], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节介绍的是GoogLeNet第一版。其基础卷积块叫做Inception.下图为Inception块中的结构。\n",
    "\n",
    "Inception块里有4条并行的线路。前3条线路使用窗口大小分别是$1\\times 1$、$3\\times 3$和$5\\times 5$的卷积层来抽取不同空间尺寸下的信息，其中中间2个线路会对输入先做$1\\times 1$卷积来减少输入通道数，以降低模型复杂度。第四条线路则使用$3\\times 3$最大池化层，后接$1\\times 1$卷积层来改变通道数。4条线路都使用了合适的填充来使输入与输出的高和宽一致。最后我们将每条线路的输出在通道维上连结，并输入接下来的层中去。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/class7_5.1.svg\" style=\"zoom:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T08:22:29.790540Z",
     "start_time": "2020-03-30T08:22:29.786541Z"
    }
   },
   "source": [
    "GoogLeNet跟VGG一样，在主体卷积部分中使用5个模块（block），每个模块之间使用步幅为2的$3\\times 3$最大池化层来减小输出高宽。第一模块使用一个64通道的$7\\times 7$卷积层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结:\n",
    "\n",
    "1. Inception块相当于一个有4条线路的自网络。它通过不同窗口形状的Conv2D和MaxPool来并行抽取信息，并使用1x1卷积层减少通道数从而降低模型复杂度\n",
    "2. GoogLeNet将多个设计惊喜的Inception块和其他层串联起来。其中Inception块内的通道数分配之比是在ImageNet数据集上通过大量实验得出的\n",
    "3. GoogLeNet和它的升级版是非常高效的模型，在类似的精度测试下，它们的计算复杂度往往更低"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:31:07.288702Z",
     "start_time": "2020-03-30T09:31:07.285809Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:31:07.461652Z",
     "start_time": "2020-03-30T09:31:07.450843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inception块\n",
    "class Inception(tf.keras.layers.Layer):\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super().__init__()\n",
    "        # 线路1, 单1x1卷积层\n",
    "        self.p1_1 = Conv2D(c1, kernel_size=1, padding='same', activation='relu')\n",
    "        \n",
    "        # 线路2, 1x1卷积层 后接 3x3卷积层\n",
    "        self.p2_1 = Conv2D(c2[0], kernel_size=1, padding='same', activation='relu')\n",
    "        self.p2_2 = Conv2D(c2[1], kernel_size=3, padding='same', activation='relu')\n",
    "        \n",
    "        # 线路3, 1x1卷积层 后接 5x5卷积层\n",
    "        self.p3_1 = Conv2D(c3[0], kernel_size=1, padding='same', activation='relu')\n",
    "        self.p3_2 = Conv2D(c3[1], kernel_size=5, padding='same', activation='relu')\n",
    "        \n",
    "        # 线路4, 3x3最大池化 后接 1x1卷积层\n",
    "        self.p4_1 = MaxPool2D(pool_size=3, padding='same', strides=1)\n",
    "        self.p4_2 = Conv2D(c4, kernel_size=1, padding='same', activation='relu')\n",
    "    \n",
    "    def call(self, x):\n",
    "        # 其实就相当于, x为这个块的输入\n",
    "        # 然后四条path对x输入都有不同的输出\n",
    "        # 最终的正向传播的结果是把这四条path的结果给concat起来\n",
    "        # 具体原理参见5.DL计算\n",
    "        # 其中p1-4 为 第1-4条path输出的结果\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        return tf.concat([p1, p2, p3, p4], axis=-1)  # 在通道维上连结输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:31:07.627391Z",
     "start_time": "2020-03-30T09:31:07.616821Z"
    }
   },
   "outputs": [],
   "source": [
    "# GoogLeNet模型\n",
    "\n",
    "def googlenet():\n",
    "    \n",
    "    # block1 ~ Conv2D + MaxPool\n",
    "    b1 = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=7, strides=2, padding='same', activation='relu'),\n",
    "        MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "    ])\n",
    "    \n",
    "    # block2 ~ Conv2D + Conv2D + MaxPool\n",
    "    b2 = tf.keras.models.Sequential([\n",
    "        Conv2D(filters=64, kernel_size=1, strides=1, padding='same', activation='relu'),\n",
    "        Conv2D(filters=192, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
    "        MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "    ])\n",
    "    \n",
    "    # block3 ~ Inception*2 + MaxPool\n",
    "    b3 = tf.keras.models.Sequential([\n",
    "        Inception(64, (96, 128), (16, 32), 32),\n",
    "        Inception(128, (128, 192), (32, 96), 64),\n",
    "        MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "    ])\n",
    "    \n",
    "    # block4 ~ Inception*5 + MaxPool\n",
    "    b4 = tf.keras.models.Sequential([\n",
    "        Inception(192, (96, 208), (16, 48), 64),\n",
    "        Inception(160, (112, 224), (24, 64), 64),\n",
    "        Inception(128, (128, 256), (24, 64), 64),\n",
    "        Inception(112, (144, 288), (32, 64), 64),\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        MaxPool2D(pool_size=3, strides=2, padding='same')\n",
    "    ])\n",
    "    \n",
    "    # block5 ~ Inception*2 + GlobalAvgPool\n",
    "    b5 = tf.keras.models.Sequential([\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        Inception(384, (192, 384), (48, 128), 128),\n",
    "        GlobalAveragePooling2D() # 使每个通道的高和宽变为1，其值为该通道的平均值\n",
    "    ])\n",
    "    \n",
    "    # output ~ FC\n",
    "    net = tf.keras.models.Sequential([\n",
    "        b1, b2, b3, b4, b5, Dense(10)\n",
    "    ])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:31:08.080521Z",
     "start_time": "2020-03-30T09:31:07.788852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential_37 output shape:\t (1, 24, 24, 64)\n",
      "sequential_37 output shape:\t (1, 12, 12, 192)\n",
      "sequential_37 output shape:\t (1, 6, 6, 480)\n",
      "sequential_37 output shape:\t (1, 3, 3, 832)\n",
      "sequential_37 output shape:\t (1, 1024)\n",
      "sequential_37 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# 构造一个高和宽为96的单通道数据样本观察每一层的形状\n",
    "\n",
    "GoogLeNet = googlenet()\n",
    "X = tf.random.uniform(shape=(1, 96, 96, 1))\n",
    "for layer in GoogLeNet.layers:\n",
    "    X = layer(X)\n",
    "    print(GoogLeNet.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:31:40.867950Z",
     "start_time": "2020-03-30T09:31:08.890720Z"
    }
   },
   "outputs": [],
   "source": [
    "# 获取数据与训练模型\n",
    "\n",
    "def get_data():\n",
    "    # 获取数据\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    # 修改数据shape (channel=1)\n",
    "    train_images = tf.reshape(train_images, (train_images.shape[0],train_images.shape[1],train_images.shape[2], 1))\n",
    "    test_images = tf.reshape(test_images, (test_images.shape[0],test_images.shape[1],test_images.shape[2], 1))\n",
    "\n",
    "    # pad图像shape至244,244\n",
    "    train_images = tf.image.resize_with_pad(train_images, 224, 224, )\n",
    "    test_images = tf.image.resize_with_pad(test_images, 224, 224, )\n",
    "    \n",
    "    # 标准化图像\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T09:32:44.709011Z",
     "start_time": "2020-03-30T09:32:22.468681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 - 22s - loss: 1.7944 - accuracy: 0.3060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7944151592254638, 0.306]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练网络\n",
    "\n",
    "GoogLeNet.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-7),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "# GoogLeNet.fit(x=train_images,\n",
    "#               y=train_labels,\n",
    "#               batch_size=128,\n",
    "#               epochs=5,\n",
    "#               verbose=2)\n",
    "\n",
    "# 因为CPU训练要很久，所以用GPU训练完了把weights拿过来\n",
    "GoogLeNet.load_weights('files/class7_5_weights.h5')\n",
    "\n",
    "# 查看test集前2000的准确率\n",
    "GoogLeNet.evaluate(test_images[:2000], test_labels[:2000], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重点总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LeNet: (Conv + MaxPool) $\\times$ 2 + Flatten + Dense $\\times$ 3\n",
    "- AlexNet: (Conv + MaxPool) $\\times$ 2 + (Conv $\\times$ 3 + MaxPool) + Flatten + (Dense + DropOut) $\\times$ 2 + Dense\n",
    "- VGG: VGG_block $\\times$ N + Flatten + (Dense + DropOut) $\\times$ 2 + Dense\n",
    "    - VGG_block: Conv $\\times$ n + MaxPool\n",
    "- NiN: (NiN_block + MaxPool) $\\times$ 3 + DropOut + NiN_block + GlobalAvgPool + Flatten\n",
    "    - NiN_block: Conv + 1$\\times$1Conv + 1$\\times$1Conv\n",
    "- GoogLeNet: Conv + MaxPool + Conv $\\times$ 2 + MaxPool + Inception $\\times$ 2 + MaxPool + Inception $\\times$ 5 + MaxPool + Inception $\\times$ 2 + GlobalAvgPool\n",
    "    - Inception_block: \n",
    "        1. 1$\\times$1 Conv\n",
    "        2. 1$\\times$1 Conv + Conv\n",
    "        3. 1$\\times$1 Conv + Conv\n",
    "        4. MaxPool + 1$\\times$1 Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
